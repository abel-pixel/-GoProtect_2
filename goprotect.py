# -*- coding: utf-8 -*-
"""goprotect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13mxRXWc1qwYjRqW9kc5eMO5i6CJ8KMFx

# Проект для GoProtect

<h1>Содержание<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Описание-проекта" data-toc-modified-id="Описание-проекта-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Описание проекта</a></span><ul class="toc-item"><li><span><a href="#Цель-проекта" data-toc-modified-id="Цель-проекта-1.1"><span class="toc-item-num">1.1&nbsp;&nbsp;</span>Цель проекта</a></span></li><li><span><a href="#Постановка-задачи" data-toc-modified-id="Постановка-задачи-1.2"><span class="toc-item-num">1.2&nbsp;&nbsp;</span>Постановка задачи</a></span></li><li><span><a href="#Описание-данных" data-toc-modified-id="Описание-данных-1.3"><span class="toc-item-num">1.3&nbsp;&nbsp;</span>Описание данных</a></span></li></ul></li><li><span><a href="#Загрузка-необходимых-библиотек-и-функций" data-toc-modified-id="Загрузка-необходимых-библиотек-и-функций-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Загрузка необходимых библиотек и функций</a></span></li><li><span><a href="#Загрузка-данных" data-toc-modified-id="Загрузка-данных-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href="#Изучение-данных" data-toc-modified-id="Изучение-данных-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Изучение данных</a></span><ul class="toc-item"><li><span><a href="#Формирование-и-изучение-отчета-о-данных" data-toc-modified-id="Формирование-и-изучение-отчета-о-данных-4.1"><span class="toc-item-num">4.1&nbsp;&nbsp;</span>Формирование и изучение отчета о данных</a></span></li><li><span><a href="#Промежуточные-выводы" data-toc-modified-id="Промежуточные-выводы-4.2"><span class="toc-item-num">4.2&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href="#Предобработка-данных" data-toc-modified-id="Предобработка-данных-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class="toc-item"><li><span><a href="#Устранение-явных-дубликатов" data-toc-modified-id="Устранение-явных-дубликатов-5.1"><span class="toc-item-num">5.1&nbsp;&nbsp;</span>Устранение явных дубликатов</a></span></li></ul></li><li><span><a href="#Подготовка-данных" data-toc-modified-id="Подготовка-данных-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href="#Создание-модели" data-toc-modified-id="Создание-модели-7"><span class="toc-item-num">7&nbsp;&nbsp;</span>Создание модели</a></span></li><li><span><a href="#Проверка-модели-на-тестовых-данных" data-toc-modified-id="Проверка-модели-на-тестовых-данных-8"><span class="toc-item-num">8&nbsp;&nbsp;</span>Проверка модели на тестовых данных</a></span></li><li><span><a href="#Итоговые-выводы" data-toc-modified-id="Итоговые-выводы-9"><span class="toc-item-num">9&nbsp;&nbsp;</span>Итоговые выводы</a></span><ul class="toc-item"><li><span><a href="#Отчет-о-проделанной-работе" data-toc-modified-id="Отчет-о-проделанной-работе-9.1"><span class="toc-item-num">9.1&nbsp;&nbsp;</span>Отчет о проделанной работе</a></span></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-9.2"><span class="toc-item-num">9.2&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li></ul></div>

## Описание проекта

### Цель проекта

Цель данного проекта - разработать модель для стандартизации названий спортивных школ.

### План работы

Сервис "Мой Чемпион" помогает спортивным школам фигурного катания, тренерам мониторить результаты своих подопечных и планировать дальнейшее развитие спортсменов. Проблема состоит в том, что одна и та же школа может быть записана в данных по разному. Надо сопоставить варианты написаний эталонному названию из предоставленной заказчиком таблицы.

Необходимо:
1. Изучить данные – эталонные названия спортивных школ и варианты пользовательского ввода.
2. Подготовить обучающий набор данных на основе эталонного датасета.
3. Создать модель для подбора наиболее вероятных названий при ошибочном вводе.
4. Создать функцию (класс, модуль) для применения в сервисе:
    - возможность выбора количества кандидатов,
    - вывод в виде списка словарей.
5. Протестировать решение.
6. Проанализировать результат и предложить варианты улучшения.
7. Создать документацию:
    - описание признаков,
    - какая модель используется,
    - как оценивается качество,
    - инструкция по запуску (применению).

### Описание данных

Данные находятся в файлах:
* `Примерное написание.csv` - описание школ,
* `Школы.csv` - эталонный датасет.

Признаки:
* Датасет `Примерное написание.csv`:
    - `school_id` - идентификатор школы,
    - `name`- описание школы.    
* Датасет `Школы.csv`:
    - `school_id` - идентификатор школы,
    - `name`- название школы,
    - `region`- название региона.

##  Загрузка необходимых библиотек и функций
"""

! python -m pip install -U pip -q
! pip install matplotlib==3.4.2 -q
! pip install missingno -q
! pip install numba==0.57.1 -q
! pip install numpy==1.23 -q
! pip install pandas==2.0.3 -q
! pip install sentence_transformers -q

import os
import re
import time
import warnings

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from tqdm import notebook

from sentence_transformers import SentenceTransformer
from sentence_transformers.util import semantic_search


import missingno as msno

warnings.filterwarnings("ignore");

RANDOM_STATE = 12345;

def df_research_method(df, method):
    """
    Применяет определенный метод изучения данных в датасете.

    Параметры:
    - df: Исследуемый датасет.
    - method: Название метода.

    Пример:
    ```
    df_research_method(df, 'head')
    ```
    """

    if method == 'head':
        display(df.head())
    elif method == 'sample':
        display(df.sample(10 ))
    elif method == 'shape':
        display(df.shape)
    elif method == 'describe':
        display(df.describe(include='all').T)
    elif method == 'duplicated':
        dp = df.duplicated().sum()
        display(dp)
        if dp > 0:
            print('Количество явных дубликатов:')
            display(df[df.duplicated()])
    elif method == 'unique':
        # for column in df.select_dtypes(include='object').columns:
        for column in df.columns:
            df_true = df[column].notnull()
            df_all = df.loc[df_true, column].count()

            df_temp = df.loc[df_true, column].sort_values().unique()
            if df_all != len(df_temp):
                print(f'Количество уникальных значений в колонке {column}: {len(df_temp)} всего {df_all}')
                # print(f'Уникальные значения в колонке {column}: {df_temp}')
    elif method == 'msno':
        display(msno.bar(df))
        plt.show()
    else:
        display(df.info())

# Функция применения методов к списку датасетов
def df_research(df_list, df_methods):
    """
    Применяет метод из списка для изучения данных в списке датасетов.

    Параметры:
    - df_list: Список исследуемых датасетов (имя переменной, описание, имя файла).
    - df_method: Список названий методов.

    Пример:
    ```
    df_research(df_list, df_methods)
    ```
    """

    for method in df_methods:
        print(f'Изучим {method[1]}:')
        print('-' * 70)
        for df in df_list:
            print('Dataset:', df[1])
            print('-' * 70)
            globals()[df[0]] = globals()[df[0]].applymap(lambda x: x.lower() if isinstance(x, str) else x)
            df_research_method(globals()[df[0]], method[0])
            print('-' * 70);

"""## Загрузка данных"""

# Список датасетов для загрузки -
# имя переменной датасета, описание датасета, имя файла
datasets = [
    ['descriptions', 'описание школ', 'Примерное написание.csv', []],
    ['schools', 'эталонный датасет', 'Школы.csv', []]
]

# Пути для загрузки
dirs = [
    'c:/dev/DS_gp/'
];

# Проведем загрузку
for df in datasets:
    ok = False
    for dir in dirs:
        path = f'{dir}{df[2]}'
        if os.path.exists(path):
            globals()[df[0]] = pd.read_csv(path, sep=',', decimal='.', parse_dates=df[3])
            ok = True
            break
    if not ok:
        print(f'Ошибка загрузки датасета "{df[1]}"')
        break
    print(f'Датасет "{df[1]}" загружен 100%');

"""## Изучение данных

### Формирование и изучение отчета о данных

Подготовим спискок методов изучения данных:
"""

df_methods = [['info', 'общую информацию о датасете'],
              ['head', 'начальные записи датасета'],
              ['shape', 'размеры датасета'],
              ['describe', 'описание полей датасета'],
              ['duplicated', 'явные дубликаты'],
              ['unique', 'уникальные значения'],
              ['msno', 'пропуски']
             ];

"""Изучим данные:"""

df_research(datasets, df_methods);

"""### Промежуточные выводы

В ходе загрузки и изучения данных выявили, что:
- Пропуски в данных не выявлены.
- Выявлены явные дубликаты.

##  Предобработка данных

### Устранение явных дубликатов
"""

# Удаление дубликатов
descriptions.drop_duplicates(inplace=True);
schools.drop_duplicates(inplace=True);

# Проверка результата
print(f'Количество явных дубликатов: {descriptions.duplicated().sum()}')
print(f'Количество явных дубликатов: {schools.duplicated().sum()}');

"""## Подготовка данных

Сформируем новый датасет и новое поле из эталонного датасета:
"""

df = schools[['school_id', 'name', 'region']]
df['name_new'] = df['name'] + ' ' + df['region']
display(df);

"""Очистим поле от ненужных символов:"""

df['name_new'] = (df['name_new']
                  .replace(r'\(.+\)' , ' ', regex=True)
                  .replace(r'[^A-Яа-яёЁA-Za-z0-9\s]', ' ', regex=True)
                  .replace(r'\s+', ' ', regex=True)
                  .str.strip())
display(df);

"""Создадим свою функцию для аугментации:"""

def my_aug(text, n=1):
    sims = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'
    a_list = []
    ar = text.split()
    k = len(ar)
    if n > 33:
        n = 33
    for i in range(n):
        if i >= k:
            ar.append(sims[i])
        else:
            ar = ar[1:] + ar[:1]
        s = ' '.join(map(str, ar))
        if i == 1:
            s = 'а' + s
        if i == n-1:
            s += 'а'
        a_list.append(s)
    return a_list;

"""Проведем аугментацию и сохраним в новый датасет:"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# df['augmented'] = ''
# for i in notebook.tqdm(range(df.shape[0])):
#     df['augmented'][i] = my_aug(df['name_new'][i], 20)
# df_aug = df.explode('augmented')[['school_id', 'name_new', 'augmented']].reset_index(drop=True)
# display(df_aug);

"""## Создание модели"""

model = SentenceTransformer('sentence-transformers/LaBSE')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# corpus = model.encode(df_aug.augmented.values)
# query = model.encode(descriptions.name.values)

"""Создадим фнукцию для получения результатов поиска:"""

def get_search_result(query, corpus, top_k=3):
    return semantic_search(query, corpus, top_k=3)

search_result = get_search_result(query, corpus, top_k=3)
display(search_result[:10])

"""## Проверка модели на тестовых данных

Создадим функцию для опрееления лучшего "кандидата":
"""

def max_result(data):
    i = sorted(data, key=lambda d: d['score'])
    return i[-1]['corpus_id']

"""Создадим поля для проверки качества модели:"""

descriptions['candidate_idx'] = [max_result(x) for x in search_result]
descriptions['candidate_school_id'] = df_aug.school_id.values[descriptions.candidate_idx.values]
descriptions['candidate_name'] = df_aug.name_new.values[descriptions.candidate_idx.values]
display(descriptions)

result = round((descriptions.school_id == descriptions.candidate_school_id).sum()/descriptions.shape[0], 2)
print('Доля правильного определения наименований школ:', result)

"""## Итоговые выводы

### Отчет о проделанной работе

**Цель данного проекта - разработать модель для стандартизации названий спортивных школ.**

**В ходе загрузки и изучения данных:**
* Проведена загрузка.
* В ходе изучения данных выявили, что:
    - Пропуски в данных не выявлены.
    - Выявлены и удалены явные дубликаты.
    
**В ходе подготовки данных:**
* добавлен новый признак,
* проведена аугментация данных.

**Использована модель `SentenceTransformer`**.
   
**Результаты:**
* Доля правильного определения наименований школ: 0.78.

### Выводы

**Модель `SentenceTransformer` рекомендована заказчику как базовый вариант для стандартизации названий спортивных школ.**

*В дальнейшем планируется разработать и протестировать другие модели, и провести их сравнение с базовым вариантом.*
"""